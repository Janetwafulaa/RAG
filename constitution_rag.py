# -*- coding: utf-8 -*-
"""Constitution RAG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EoqxYZUcaMHslksqfmDby9SmvfpjDIt-

# CONSTITUTION OF KENYA RAG
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install langchain-groq langchain sentence-transformers langchain-community  pypdf chromadb

#importing libraries
from sentence_transformers import SentenceTransformer
from langchain.retrievers import ParentDocumentRetriever
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain.storage import InMemoryStore
from langchain_groq import ChatGroq

doc_path="/content/The_Constitution_of_Kenya_2010.pdf"
loader= PyPDFLoader(doc_path)
docs=loader.load()
print(len(docs))

#initializing parent and text splitters
parent_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1500,
    chunk_overlap=100,
)

child_splitter = RecursiveCharacterTextSplitter(
    chunk_size=700,
    chunk_overlap=50,
)

#initializing the embedding model
bge_model=SentenceTransformer("BAAI/bge-base-en-v1.5")
class BGEEmbeddings:
  def embed_documents(self, text):
    return bge_model.encode(text,batch_size=8,normalize_embeddings=True).tolist()
  def embed_query(self, query):
    return bge_model.encode([query],normalize_embeddings=True).tolist()[0]



#creating the vector store
constitution_vector_store=Chroma(
    collection_name="constitution",
    embedding_function=BGEEmbeddings(),
    persist_directory="./chroma",
)

#creating in-memory store
store=InMemoryStore()

#creating retrievers
retriever=ParentDocumentRetriever(
    vectorstore=constitution_vector_store,
    docstore=store,
    child_splitter=child_splitter,
    parent_splitter=parent_splitter,
)

#adding documents into the vector store
retriever.add_documents(docs)

#creating a child retriever
child_retriever=constitution_vector_store.as_retriever()

#initializing the LLM
llm=ChatGroq(
   groq_api_key=userdata.get('constitution_of_kenya'),
   model_name="llama-3.3-70b-versatile",
   temperature=0.7

)

#creating the template
template="""
 Answer the following questions according to the context given.
 If the question is out of context,just say the question is out of context Kindly give me another question.
 Do not try to answer a question out of context.
 {context}
 Question: {question}
"""

#creating the chain
qa_chain=PromptTemplate(template=template,input_variables=["context","question"])

chain=RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type_kwargs={"prompt":qa_chain},
    return_source_documents=True
)

question="How many levels of government are established under the Constitution of Kenya 2010?"
answer=chain({"query":question})
print(answer["result"])

question="What does Article 27 say about equality and freedom from discrimination?"
answer=chain({"query":question})
print(answer["result"])